{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/moseskim/bert_nlp/blob/main/section_2/01_pytorch_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"Niaz8_W6OX34"},"source":["# PyTorch 기초\n","\n","PyTorch 기초를 학습하기 위해 신경망을 훈련시켜 손으로 쓴 문자를 인식해봅니다.\n"]},{"cell_type":"markdown","metadata":{"id":"x9Gzbn25XSlF"},"source":["## 데이터 로딩\n","\n","`torchvision.datasets`를 사용해 손으로 쓴 문자 데이터를 로딩하고, **DataLoader**를 설정합니다.  \n","`DataLoader`를 사용하면 데이터 로딩이나 미니 배치 알고리즘 구현을 매우 쉽게 할 수 있습니다.  \n","`torchvision.datasets`에는 MNIST 외에도 다양한 데이터셋이 준비되어 있습니다.  \n","https://pytorch.org/docs/stable/torchvision/datasets.html"]},{"cell_type":"code","metadata":{"id":"81Il03RNAmbS"},"source":["import torch\n","from torchvision.datasets import MNIST  # 손으로 쓴 문자 이미지 데이터\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","\n","# 훈련 데이터 취득\n","mnist_train = MNIST(\"./data\",\n","                    train=True, download=True,\n","                    transform=transforms.ToTensor())\n","# 테스트 데이터 취득\n","mnist_test = MNIST(\"./data\",\n","                   train=False, download=True,\n","                   transform=transforms.ToTensor())\n","print(\"훈련 데이터 수: \", len(mnist_train), \"테스트 데이터 수: \", len(mnist_test))\n","\n","# DataLoader 설정\n","img_size = 28\n","batch_size = 256\n","train_loader = DataLoader(mnist_train,\n","                          batch_size=batch_size,\n","                          shuffle=True)\n","test_loader = DataLoader(mnist_test,\n","                         batch_size=batch_size,\n","                         shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sFWHMOf2D4b1"},"source":["손으로 쓴 문자의 이미지 크기는 28x28이 됩니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FalXNYaJPkoE"},"source":["## 모델 구축\n","\n","여기에서는 `nn.Module` 모듈을 상속한 클래스로 모델을 구축합니다.  \n","`.cuda()`에 의해 모델의 계산은 GPU 상에서 수행됩니다."]},{"cell_type":"code","metadata":{"id":"SuqqZmsh_jNK"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(img_size*img_size, 1024)  # 전결합층\n","        self.fc2 = nn.Linear(1024, 512)\n","        self.fc3 = nn.Linear(512, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, img_size*img_size)  # 배치 크기 x 입력 수\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","net = Net()\n","net.cuda()  # GPU 대응\n","print(net)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qsW5zCKhQE9p"},"source":["## 학습\n","\n","모델을 훈련합니다.  \n","`DataLoader`를 사용해 미니 배치를 꺼내서 훈련 및 평가를 수행합니다.\n","\n","1 에폭 안에서 여러 차례 미니 배치를 사용해 훈련이 수행되고, 미니 배치 알고리즘이 구현되게 됩니다.  \n","학습에는 시간이 걸리므로 수정 → 노트 설정 → 하드웨어 가속기에 GPU가 선택되어 있는 것을 확인합니다.\n"]},{"cell_type":"code","metadata":{"id":"u6zwN3nArbGC"},"source":["from torch import optim\n","\n","# 교차 엔트로비피 오차 함수\n","loss_fnc = nn.CrossEntropyLoss()\n","\n","# SGD\n","optimizer = optim.SGD(net.parameters(), lr=0.01)\n","\n","# 손실 로그\n","record_loss_train = []\n","record_loss_test = []\n","\n","# 학습\n","for i in range(10):  # 10 에폭 학습\n","    net.train()  # 훈련 모드\n","    loss_train = 0\n","    for j, (x, t) in enumerate(train_loader):  # 미니 배치(x, t)를 꺼낸다\n","        x, t = x.cuda(), t.cuda()  # GPU 대응\n","        y = net(x)\n","        loss = loss_fnc(y, t)\n","        loss_train += loss.item()\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    loss_train /= j+1\n","    record_loss_train.append(loss_train)\n","\n","    net.eval()  # 평가 모드\n","    loss_test = 0\n","    for j, (x, t) in enumerate(test_loader):  # 미니 배치(x, t)를 꺼낸다\n","        x, t = x.cuda(), t.cuda()\n","        y = net(x)\n","        loss = loss_fnc(y, t)\n","        loss_test += loss.item()\n","    loss_test /= j+1\n","    record_loss_test.append(loss_test)\n","\n","    if i%1 == 0:\n","        print(\"Epoch:\", i, \"Loss_Train:\", loss_train, \"Loss_Test:\", loss_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rJwwrWTw43rx"},"source":["## 오차 추이\n","\n","훈련 데이터, 테스트 데이터로 오차 추이를 그래프로 표시합니다."]},{"cell_type":"code","metadata":{"id":"OaJx4swE45XI"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(range(len(record_loss_train)), record_loss_train, label=\"Train\")\n","plt.plot(range(len(record_loss_test)), record_loss_test, label=\"Test\")\n","plt.legend()\n","\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Error\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iMrpac0m4Nct"},"source":["## 정답율\n","\n","모델의 성능을 파악하기 위해 테스트 데이터를 사용해 정답율을 측정합니다."]},{"cell_type":"code","metadata":{"id":"IRkGCYMM_N35"},"source":["correct = 0\n","total = 0\n","for i, (x, t) in enumerate(test_loader):\n","    x, t = x.cuda(), t.cuda()  # GPU 대응\n","    x = x.view(-1, img_size*img_size)\n","    y = net(x)\n","    correct += (y.argmax(1) == t).sum().item()\n","    total += len(x)\n","print(\"정답율: \", str(correct/total*100) + \"%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bs5MIx_EVrZk"},"execution_count":null,"outputs":[]}]}