{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/moseskim/bert_nlp/blob/main/section_2/03_simple_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"uv454lBK1YCc"},"source":["# 간단한 BERT 구현\n","\n","훈련 완료 모델을 사용해 문장의 일부를 예측하고, 2개의 문장이 연속되어 있는지 판정합니다."]},{"cell_type":"markdown","metadata":{"id":"L_Ozfz3NhltP"},"source":["## 라이브러리 설치\n","\n","PyTorch-Transformers 및 필요한 라이브러리를 설치합니다."]},{"cell_type":"code","metadata":{"id":"Y_mDYVlb-sqi"},"source":["!pip install folium==0.2.1\n","!pip install urllib3==1.25.11\n","!pip install pytorch-transformers==1.2.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gb5gVyYF2vjL"},"source":["## 문장 일부 예측\n","\n","문자에서 일부 단어를 MASK하고, BERT 모델을 사용해 그 단어를 예측합니다."]},{"cell_type":"code","metadata":{"id":"G6oFZnS21Mqs"},"source":["import torch\n","from pytorch_transformers import BertForMaskedLM\n","from pytorch_transformers import BertTokenizer\n","\n","\n","text = \"[CLS] I played baseball with my friends at school yesterday [SEP]\"\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","words = tokenizer.tokenize(text)\n","print(words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t3Y32Tl55dSl"},"source":["문장 일부를 MASK합니다."]},{"cell_type":"code","metadata":{"id":"0_H50V7b5RM0"},"source":["msk_idx = 3\n","words[msk_idx] = \"[MASK]\"  # 단어를 [MASK]로 치환한다\n","print(words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xBXgAn9s528_"},"source":["단어를 대응하는 인덱스로 변환합니다."]},{"cell_type":"code","metadata":{"id":"zm4qbMPW56-w"},"source":["word_ids = tokenizer.convert_tokens_to_ids(words)  # 단어를 인덱스로 변환\n","word_tensor = torch.tensor([word_ids])  # 텐서로 변환\n","print(word_tensor)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y76O88877cB_"},"source":["BERT 모델을 사용해 예측을 수행합니다."]},{"cell_type":"code","metadata":{"id":"M2NWREc77gQC"},"source":["msk_model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n","msk_model.cuda()  # GPU 대응\n","msk_model.eval()\n","\n","x = word_tensor.cuda()  # GPU 대응\n","y = msk_model(x)  # 예측\n","result = y[0]\n","print(result.size())  # 결과의 형태\n","\n","_, max_ids = torch.topk(result[0][msk_idx], k=5)  # 가장 큰 5개의 값\n","result_words = tokenizer.convert_ids_to_tokens(max_ids.tolist())  # 인덱스를 단어로 변환\n","print(result_words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2Su6QTCAAgFS"},"source":["## 문장이 연속되어 있는지 판정\n","\n","BERT 모델을 사용해 2개의 문장이 연속되어 있는지 판정합니다.  \n","다음의 함수 `show_continuity`에서는 2개 문장의 연속성을 판정하고 표시합니다.  "]},{"cell_type":"code","metadata":{"id":"FC0nihWMAtgG"},"source":["from pytorch_transformers import BertForNextSentencePrediction\n","\n","def show_continuity(text, seg_ids):\n","    words = tokenizer.tokenize(text)\n","    word_ids = tokenizer.convert_tokens_to_ids(words)  # 단어를 인덱스로 변환\n","    word_tensor = torch.tensor([word_ids])  # 텐서로 변환\n","\n","    seg_tensor = torch.tensor([seg_ids])\n","\n","    nsp_model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n","    nsp_model.cuda()  # GPU 대응\n","    nsp_model.eval()\n","\n","    x = word_tensor.cuda()  # GPU 대응\n","    s = seg_tensor.cuda()  # GPU 대응\n","\n","    y = nsp_model(x, s)  # 예측\n","    result = torch.softmax(y[0], dim=1)\n","    print(result)  # Softmax로 확률로\n","    print(str(result[0][0].item()*100) + \"%의 확률로 연속됩니다.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wWogb8nFIQMg"},"source":["`show_continuity` 함수에 자연스럽게 이어지는 2개의 문장을 전달합니다."]},{"cell_type":"code","metadata":{"id":"OaUmof1yF_rD"},"source":["text = \"[CLS] What is baseball ? [SEP] It is a game of hitting the ball with the bat [SEP]\"\n","seg_ids = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ,1, 1]  # 0: 앞 문장의 단어, 1: 뒷 문장의 단어\n","show_continuity(text, seg_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LKjotaOCIeeK"},"source":["`show_continuity` 함수에 자연스럽게 이어지지 않는 2개의 문장을 전달합니다."]},{"cell_type":"code","metadata":{"id":"v4qAKBlcGRYb"},"source":["text = \"[CLS] What is baseball ? [SEP] This food is made with flour and milk [SEP]\"\n","seg_ids = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]  # 0: 앞 문장의 단어, 1: 뒷 문장의 단어\n","show_continuity(text, seg_ids)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"o3y5bNOqaeXw"},"execution_count":null,"outputs":[]}]}